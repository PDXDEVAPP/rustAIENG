# ğŸš€ Rust Ollama Development Setup Guide

This guide provides multiple ways to set up and run your Rust Ollama development environment with all dependencies up to date.

## ğŸ“‹ Prerequisites

Make sure you have the following installed:

- **Rust/Cargo**: Install via [rustup.rs](https://rustup.rs/)
- **Node.js 18+**: Install from [nodejs.org](https://nodejs.org/)
- **npm**: Usually comes with Node.js
- **Git**: For version control
- **SQLite3**: For the database

## ğŸ› ï¸ Setup Options

### Option 1: Complete Setup (Recommended)

**Run the comprehensive setup script:**
```bash
./dev-setup-complete.sh
```

This script will:
- âœ… Install Rust and Node.js if missing
- âœ… Create development directories and configuration
- âœ… Update all dependencies to latest versions
- âœ… Build both backend and frontend
- âœ… Test the setup automatically
- âœ… Provide startup scripts

### Option 2: Detailed Setup

**Run the comprehensive development setup:**
```bash
./dev-setup-comprehensive.sh
```

This provides detailed step-by-step setup with:
- âœ… Dependency checking and updates
- âœ… Development environment configuration
- âœ… Testing utilities and monitoring scripts
- âœ… Hot reload setup for both frontend and backend

### Option 3: Quick Setup

**Run the simple setup:**
```bash
./dev-setup-simple.sh
```

For minimal setup with basic configuration.

## ğŸš€ Running the Development Environment

### One-Click Start

**Start everything at once:**
```bash
./dev-run.sh
```

This will:
- âœ… Build the project if needed
- âœ… Start the backend server on port 11435
- âœ… Test model download functionality
- âœ… Test API endpoints
- âœ… Optionally start the frontend dashboard
- âœ… Provide system monitoring

### Manual Start

**Start backend only:**
```bash
# Set environment
export DATABASE_URL="sqlite:./dev_data/ollama_dev.db"
export RUST_LOG=debug
source ~/.cargo/env

# Start server
cargo run --release -- serve --port 11435
```

**Start frontend only:**
```bash
cd dashboard
npm run dev
```

## ğŸ§ª Testing the Enhanced Backend

The enhanced backend includes real model downloading and inference capabilities:

### Test Model Download

```bash
# Download LLaMA 3.2 model
curl -X POST http://localhost:11435/api/pull \
  -H "Content-Type: application/json" \
  -d '{"name": "llama3.2"}'

# Download Mistral model  
curl -X POST http://localhost:11435/api/pull \
  -H "Content-Type: application/json" \
  -d '{"name": "mistral"}'
```

### Test API Endpoints

```bash
# Health check
curl http://localhost:11435/api/health

# List models
curl http://localhost:11435/api/models

# Generate text
curl -X POST http://localhost:11435/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.2",
    "prompt": "Hello, how are you?",
    "stream": false
  }'
```

## ğŸ“ Development Structure

```
/workspace/
â”œâ”€â”€ dev/                    # Development-specific files
â”‚   â”œâ”€â”€ models/            # Model storage for development
â”‚   â”œâ”€â”€ data/              # Development database
â”‚   â”œâ”€â”€ logs/              # Development logs
â”‚   â””â”€â”€ cache/             # Development cache
â”œâ”€â”€ dashboard/             # React frontend
â”œâ”€â”€ src/                   # Rust backend source
â”œâ”€â”€ dev_config.toml        # Development configuration
â”œâ”€â”€ .env                   # Environment variables
â””â”€â”€ dev-start-*.sh         # Development startup scripts
```

## ğŸ”§ Development Scripts Created

- `dev_start_backend.sh` - Start backend only
- `dev_start_frontend.sh` - Start frontend only  
- `dev_start_all.sh` - Start both services
- `dev_test_api.sh` - Test API endpoints
- `dev_test_frontend.sh` - Test frontend
- `dev_monitor.sh` - Monitor development environment

## ğŸ“± Access URLs

When running:
- **Dashboard**: http://localhost:3000
- **Backend API**: http://localhost:11435
- **API Documentation**: http://localhost:11435/docs
- **Health Check**: http://localhost:11435/api/health

## ğŸ› Troubleshooting

### Backend Issues

**Rust not found:**
```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
source ~/.cargo/env
```

**Build failures:**
```bash
cargo clean
cargo update
cargo build --release
```

**Port already in use:**
```bash
# Kill process using port 11435
lsof -ti:11435 | xargs kill -9
```

### Frontend Issues

**Node.js/npm issues:**
```bash
# Update npm
npm install -g npm@latest

# Clean install
cd dashboard
rm -rf node_modules package-lock.json
npm install
```

**Port 3000 already in use:**
```bash
# Kill process using port 3000
lsof -ti:3000 | xargs kill -9
```

### Database Issues

**Database errors:**
```bash
# Recreate development database
rm -f ./dev_data/ollama_dev.db
mkdir -p ./dev_data
touch ./dev_data/ollama_dev.db
chmod 666 ./dev_data/ollama_dev.db
```

## ğŸ¯ Features Enhanced

### Real Model Downloading
- âœ… HuggingFace Hub integration
- âœ… GGUF format support
- âœ… Multiple model support (LLaMA 3.2, Mistral, etc.)
- âœ… Model quantization (Q4_0, Q8_0, etc.)

### Enhanced Inference Engine
- âœ… Real Candle ML framework integration
- âœ… GPU acceleration support (CUDA/Metal)
- âœ… WebSocket streaming
- âœ… Batch processing capabilities

### Fine-tuning Support
- âœ… LoRA (Low-Rank Adaptation)
- âœ… Full model fine-tuning
- âœ… Training monitoring
- âœ… Checkpoint management

### Development Features
- âœ… Hot reload for both frontend and backend
- âœ… Real-time logging and monitoring
- âœ… Performance metrics
- âœ… Stress testing utilities

## ğŸ’¡ Development Tips

1. **Use hot reload**: Both frontend and backend support hot reloading during development
2. **Monitor performance**: Use `./dev_monitor.sh` to monitor system resources
3. **Test incrementally**: Use the testing scripts to verify functionality step by step
4. **Clean builds**: Use `cargo clean` if you encounter strange build issues
5. **Check logs**: Development logs are stored in `./dev_logs/`

## ğŸ“š Next Steps

After setup:
1. Download a test model using the API
2. Try generating text with different models
3. Experiment with fine-tuning features
4. Use the dashboard for visual management
5. Monitor performance and optimize

Happy coding! ğŸš€